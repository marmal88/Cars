{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marmal88/Cars/blob/main/Cars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhbvEzKuyC-e"
      },
      "source": [
        "# Car Identification dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7SqQvOUhk_QY",
        "outputId": "412b07c7-8a0f-44c8-bc36-28c488f42ba9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JBDwqvzxx_t",
        "outputId": "3127e583-2869-4c1b-e613-99f4bc9617f0"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3716757621.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    jupyter nbconvert Cars.ipynb --to python\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "jupyter nbconvert Cars.ipynb --to python\n",
        "pipreqs --force .\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5Zix_S7k318"
      },
      "source": [
        "# Preliminary EDA from csv\n",
        "\n",
        "This notebook was done on google colab, pathing on notebook might differ from existing repository data structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sCDWF1Ek319"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DgtAryUk31-"
      },
      "outputs": [],
      "source": [
        "names_df = pd.read_csv('/content/drive/MyDrive/cars/annotations/class_names.csv', header=None)\n",
        "names_df.rename(columns={0:\"class_names\"}, inplace=True)\n",
        "names_df.index = (np.arange(1, len(names_df) + 1))\n",
        "\n",
        "data_df = pd.read_csv('/content/drive/MyDrive/cars/annotations/cars_annos.csv', sep=\";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8MIcGXAk31_",
        "outputId": "b8bf9aa3-6b7b-462a-db41-e8848fb489dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        image   x1  y1   x2   y2  class  test                 class_names\n",
              "0  000001.jpg  112   7  853  717      1     0  AM General Hummer SUV 2000\n",
              "1  000002.jpg   48  24  441  202      1     0  AM General Hummer SUV 2000\n",
              "2  000003.jpg    7   4  277  180      1     0  AM General Hummer SUV 2000\n",
              "3  000004.jpg   33  50  197  150      1     0  AM General Hummer SUV 2000\n",
              "4  000005.jpg    5   8   83   58      1     0  AM General Hummer SUV 2000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-baf30101-d001-4b94-bc84-65079f184787\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>x1</th>\n",
              "      <th>y1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y2</th>\n",
              "      <th>class</th>\n",
              "      <th>test</th>\n",
              "      <th>class_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>112</td>\n",
              "      <td>7</td>\n",
              "      <td>853</td>\n",
              "      <td>717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>AM General Hummer SUV 2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>48</td>\n",
              "      <td>24</td>\n",
              "      <td>441</td>\n",
              "      <td>202</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>AM General Hummer SUV 2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>277</td>\n",
              "      <td>180</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>AM General Hummer SUV 2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>33</td>\n",
              "      <td>50</td>\n",
              "      <td>197</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>AM General Hummer SUV 2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>83</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>AM General Hummer SUV 2000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-baf30101-d001-4b94-bc84-65079f184787')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-baf30101-d001-4b94-bc84-65079f184787 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-baf30101-d001-4b94-bc84-65079f184787');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df = pd.merge(data_df, names_df, how='inner', left_on=\"class\", right_index=True)\n",
        "col = {x:x.lower() for x in df.columns}\n",
        "df.rename(columns=col, inplace=True)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JilQXHaLk32B",
        "outputId": "ba0fe7f7-8da2-4116-9f2c-978b60112b71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16185, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2Rw2sxgk32C",
        "outputId": "d4eea4ac-c5b9-49af-c572-f445d5212f28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of classes entire dataset 196\n",
            "total number of classes in test set 196\n",
            "total number of classes in test set 196\n"
          ]
        }
      ],
      "source": [
        "# Check to see if the dataset split is already fair by ensuring stratification of classes over the train and test set\n",
        "test_df = df.loc[df[\"test\"]==1]\n",
        "train_df = df.loc[df[\"test\"]==0]\n",
        "\n",
        "print(f\"total number of classes entire dataset {df['class'].nunique()}\")\n",
        "print(f'total number of classes in test set {test_df[\"class\"].nunique()}')\n",
        "print(f'total number of classes in test set {train_df[\"class\"].nunique()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNNBmXvgk32D"
      },
      "outputs": [],
      "source": [
        "train_df.to_csv(\"/content/drive/MyDrive/cars/annotations/train_df.csv\", index=False) # \"data/annotations/train_df.csv\"\n",
        "train_df.to_csv(\"/content/drive/MyDrive/cars/annotations/test_df.csv\", index=False)  # \"data/annotations/test_df.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-Vfnu37k32E",
        "outputId": "5cbca68d-6417-409f-e96b-6a1ab0ec67d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "007365.jpg 9 60 294 183 285 123 Dodge Dakota Crew Cab 2010\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-53e2cc1b89be>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/cars/car_ims/{img_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/cars/car_ims/007365.jpg'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Random check to see if bounding boxes are able to completely cover the car in question\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(5):\n",
        "    rand = np.random.randint(len(df))\n",
        "    img_name, x1, y1, x2, y2, _, _, class_names = df.iloc[rand,:]\n",
        "\n",
        "    width = x2-x1\n",
        "    height = y2-y1\n",
        "    print(img_name, x1, y1, x2, y2, width, height, class_names)\n",
        "    \n",
        "    img = Image.open(f'/content/drive/MyDrive/cars/car_ims/{img_name}')\n",
        "    ax=plt.subplot(1,5,i+1)\n",
        "    plt.imshow(img)\n",
        "    rect = Rectangle((x1, y1), width, height, linewidth=1.5, edgecolor='r', facecolor='none')\n",
        "    plt.gca().add_patch(rect)\n",
        "    plt.title(f\"{class_names}\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C5Bmt0Rk32H",
        "outputId": "e09055c5-a7fe-4ac2-8d97-85d0b33f6c81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['.jpg'], dtype=object)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check to see if there are different modes in the dataset RGB vs RGBA, seems like all are jpg\n",
        "df[\"image\"].apply(lambda x: os.path.splitext(x)[1]).unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz9A7W2DyGw_"
      },
      "source": [
        "# Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GPzYao2ByCnX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T, utils \n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torchvision.models import resnet101, ResNet101_Weights\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Aw9VAKsSk32J",
        "outputId": "649bb7a9-c91a-46a2-debb-fe3524296400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes is 196\n"
          ]
        }
      ],
      "source": [
        "# set parameters for training\n",
        "train_df_path = \"/content/drive/MyDrive/cars/annotations/train_df.csv\"\n",
        "train_df = pd.read_csv(train_df_path) # data/annotations/train_df.csv\n",
        "\n",
        "num_class = train_df[\"class\"].nunique()\n",
        "print(f\"Number of classes is {num_class}\")\n",
        "epochs = 30\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZkuuezStyCg-"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file:str, root_dir:str, transform=None, custom_crop=False)->Dict:\n",
        "        \"\"\" Curated Dataset function\n",
        "        Args:\n",
        "            csv_file (str): Path to the csv file with annotations.\n",
        "            root_dir (str): Directory with all the images.\n",
        "            transform (_type_, optional): Optional transform to be applied on a sample. Defaults to None.\n",
        "        Returns:\n",
        "            Dict: Sample dictionary\n",
        "        \"\"\"        \n",
        "        self.dataframe = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.custom_crop = custom_crop\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.dataframe.image[idx])\n",
        "        img = Image.open(img_name).convert(\"RGB\")\n",
        "        label = self.dataframe[\"class\"][idx]\n",
        "        left, top, right, bottom = self.dataframe.x1[idx], self.dataframe.y1[idx], self.dataframe.x2[idx], self.dataframe.y2[idx]\n",
        "        \n",
        "        if self.custom_crop:\n",
        "            img = self._custom_crop(img, left, top, right, bottom)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, torch.tensor(int(label))\n",
        "\n",
        "    def _custom_crop(self, img, left, top, right, bottom):\n",
        "        \"\"\" Custom crop function to return the boundary box image\n",
        "        Args:\n",
        "            sample (Dict): dictionary with the same information\n",
        "        Returns:\n",
        "            Image: returns the cropped image\n",
        "        \"\"\"        \n",
        "        width = right-left\n",
        "        height = bottom-top\n",
        "        img = TF.crop(img, top, left, height, width)\n",
        "\n",
        "        return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ErAdfAp_k32M"
      },
      "outputs": [],
      "source": [
        "# normalize mean and std from imagenet pretrained\n",
        "# mean and standard dev as per pre-trained imagenet dataset (https://pytorch.org/hub/pytorch_vision_resnet/)\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "transform = T.Compose([\n",
        "                T.Resize([224,224]),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=mean, std=std),\n",
        "                ])\n",
        "\n",
        "custom_crop = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_num = int(round(0.8*len(train_df)))\n",
        "valid_num = int(round(0.2*len(train_df)))\n",
        "print(f\"Number of images in train set {train_num} and validation is {valid_num}\")\n",
        "\n",
        "path_to_data = os.path.join(os.getcwd(), \"drive/MyDrive/cars/car_ims\")\n",
        "dataset = Dataset(csv_file=train_df_path, root_dir=path_to_data, transform=transform, custom_crop=custom_crop)\n",
        "\n",
        "train_set, valid_set = torch.utils.data.random_split(dataset, [train_num, valid_num])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=2, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, num_workers=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJF-HS_yAlPJ",
        "outputId": "dc2bf8e5-9625-47eb-dc38-36b3d9bed855"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in train set 6515 and validation is 1629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, (img, label) in enumerate(train_loader):\n",
        "#     if i==1:\n",
        "#       print(img)\n",
        "#       print(label)\n",
        "#       break"
      ],
      "metadata": {
        "id": "Shh-r0CgARMl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "6Fem9ZTcALb5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-e9lj4uUk32N"
      },
      "outputs": [],
      "source": [
        "class ClassifierModel(nn.Module):\n",
        "\n",
        "    def __init__(self, num_class:int):\n",
        "        \"\"\" Initializes the ClassifierModel instance\n",
        "            The super here inherits the functions from the base torch nn.Module, allowing \n",
        "            us to create layers and convolutions.\n",
        "            Added a dropout to the last linear layer and amended out_features to num_class\n",
        "        Args:\n",
        "            num_class (int): The number of classes in the classification problem.\n",
        "        \"\"\"        \n",
        "        super().__init__()\n",
        "        self.model = torchvision.models.resnet101(weights=ResNet101_Weights.IMAGENET1K_V2)\n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = nn.Sequential(nn.Dropout(0.5), nn.Linear(num_ftrs, num_class))\n",
        "\n",
        "    def forward(self, x:torch.Tensor)-> torch.Tensor:\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LmsiiN0Ok32O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f295c378-32f9-423c-a25c-c9e154a40caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth\n",
            "100%|██████████| 171M/171M [00:02<00:00, 88.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = ClassifierModel(num_class)\n",
        "if torch.cuda.is_available():\n",
        "    model.to(\"cuda\")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter(log_dir=\"/content/drive/MyDrive/cars/runs\")\n",
        "\n",
        "for e in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    for data, labels in tqdm(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, labels = data.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        optimizer.zero_grad()\n",
        "        target = model(data)\n",
        "        loss = loss_fn(target,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    print(f'Epoch {e+1} | Training Loss: {train_loss / len(train_loader)}')\n",
        "\n",
        "    valid_loss = 0.0\n",
        "    valid_correct = 0\n",
        "    model.eval()    \n",
        "    for data, labels in valid_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            data, labels = data.cuda(), labels.cuda()\n",
        "        \n",
        "        target = model(data)\n",
        "        loss = loss_fn(target,labels)\n",
        "        valid_loss = loss.item() * data.size(0)\n",
        "\n",
        "        _, predicted = torch.max(target.detach(), 1)\n",
        "        valid_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    valid_loss /= len(valid_loader)\n",
        "    valid_acc = (valid_correct / len(valid_loader.dataset)) * 100\n",
        "    writer.add_scalar(\"Loss/Val\", valid_loss, e)\n",
        "    writer.add_scalar(\"Acc/Val\", valid_acc, e)\n",
        "\n",
        "    print(f'Epoch {e+1} | Training Loss: {train_loss:.6f} | Validation Loss: {valid_loss:.6f} | Validation Accuracy: {valid_acc:.2f}%')\n",
        "    \n",
        "    if min_valid_loss > valid_loss:\n",
        "        print(f'Validation Loss Decreased ({min_valid_loss:.6f} ---> {valid_loss:.6f}) | Saving The Model')\n",
        "        min_valid_loss = valid_loss\n",
        "        \n",
        "        if custom_crop:\n",
        "            name = f\"car_model_{valid_acc:.2f}_crop\"\n",
        "        else:\n",
        "            name = f\"car_model_{valid_acc:.2f}_nocrop\"\n",
        "        torch.save(model.state_dict(), f\"/content/drive/MyDrive/cars/models/{name}.pth\")\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "WXuCqLR4e-Bp",
        "outputId": "1e798dbc-8b99-4c5d-a536-fe41da861236",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 4/204 [04:23<3:01:31, 54.46s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n",
        "tensorboard --logdir=\"/content/drive/MyDrive/cars/runs\""
      ],
      "metadata": {
        "id": "uY9AQpB3CP6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XwFp2UsFFxVN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}